{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import pyrepseq as prs\n",
    "import pyrepseq.plotting as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as hc\n",
    "import tidytcells as tt\n",
    "import warnings\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metadata and subset to TST_D7 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('data/metadata.csv')\n",
    "meta = meta[meta['tissue']=='TST_D7']\n",
    "len(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine and standardise data for TST_D7 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = sorted(meta['chain'].unique())\n",
    "meta_chains = {}\n",
    "# list of dataframes\n",
    "dfs_chains = {}\n",
    "# concatenated dataframes\n",
    "dfc_chains = {}\n",
    "\n",
    "for chain in chains:\n",
    "    meta_chain = meta[meta['chain']==chain]\n",
    "    meta_chains[chain] = meta_chain\n",
    "    \n",
    "    dfs = []\n",
    "    for i, row in tqdm(meta_chain.iterrows(), total=meta_chain.shape[0]):\n",
    "        df = pd.read_csv(\"data/\"+row['Filename_processed'], sep='\\t')\n",
    "        c = chain[0].capitalize()\n",
    "        df = df[['v_call', 'j_call',\n",
    "                 'junction_aa', 'duplicate_count',\n",
    "                 'sequence']]\n",
    "        mapper = dict(zip([\"v_call\", \"junction_aa\",\"j_call\",\"duplicate_count\", 'sequence'],\n",
    "                                    [f\"TR{c}V\", f\"CDR3{c}\",f\"TR{c}J\", \"clonal_count\", f'CDR3{c}_NT']))\n",
    "        df = prs.standardize_dataframe(df, mapper)\n",
    "        total_count = np.sum(df['clonal_count'])\n",
    "        df['clonal_frequency'] = df['clonal_count']/total_count\n",
    "        df['tissue'] = row['tissue']\n",
    "        df['chain'] = row['chain']\n",
    "        df['UIN'] = row['UIN']\n",
    "        df['sample'] = df['UIN'] + \"_\" + df['tissue'] + \"_\" + df['chain']\n",
    "        df['bioidentity'] = df[f'TR{c}V'] + df[f'CDR3{c}'] + df[f'TR{c}J']\n",
    "        dfs.append(df)\n",
    "    dfc = pd.concat(dfs).reset_index(drop=True)\n",
    "    dfs_chains[chain] = dfs\n",
    "    dfc_chains[chain] = dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define limits for down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxsize = 10000\n",
    "minsize = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform down-sampling (and print out excluded samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_chains_subsampled = {}\n",
    "\n",
    "for chain in chains:\n",
    "    \n",
    "    dfs = []\n",
    "    for sample, df in dfc_chains[chain].groupby('sample'):\n",
    "        df = df.dropna(how='all').reset_index(drop=True)\n",
    "        total_counts = df['clonal_count'].sum()\n",
    "        if total_counts>maxsize:\n",
    "            index, counts = prs.subsample(df['clonal_count'], maxsize)\n",
    "            df_subsampled = df.loc[index]\n",
    "            df_subsampled['clonal_count'] = counts\n",
    "        elif total_counts < minsize:\n",
    "            print(sample)\n",
    "            continue\n",
    "        else:\n",
    "            df_subsampled = df\n",
    "        dfs.append(df_subsampled)\n",
    "        \n",
    "    dfc = pd.concat(dfs).reset_index(drop=True)\n",
    "    dfc_chains_subsampled[chain] = dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print out number of included samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_chains_subsampled['alpha'].drop_duplicates('sample')['chain'].value_counts(), dfc_chains_subsampled['beta'].drop_duplicates('sample')['chain'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chain in chains:\n",
    "    df = dfc_chains_subsampled[chain].copy()\n",
    "    chain_letter = chain[0].upper()\n",
    "    df[f'TR{chain_letter}Vshort'] = df[f'TR{chain_letter}V'].copy()\n",
    "    df[f'TR{chain_letter}V'] = df[f'TR{chain_letter}V'].apply(lambda s: str(s)+'*01')\n",
    "    df = df[df[f'TR{chain_letter}V'].str.startswith(f'TR{chain_letter}V')].copy()\n",
    "    df.to_csv(f'data/combined_subsampled_{minsize}_{maxsize}_{chain}.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
