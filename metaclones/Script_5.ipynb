{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "import igraph\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "import pyrepseq as prs\n",
    "import pyrepseq.plotting as pp\n",
    "from metaclonotypist import *\n",
    "\n",
    "plt.style.use('seaborn-v0_8-paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change here to define chain and MHC class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = 'beta' # needs to be in ['alpha','beta']\n",
    "mhc_class = 'II' # need to be in ['both','I','II']\n",
    "dir_out = f\"metaclonotypist_{chain}_mhc{mhc_class}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TCR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_letter = chain[0].upper()\n",
    "\n",
    "df = pd.read_csv(f'data/combined_subsampled_5000_10000_{chain}.csv.gz')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna(subset=[f'TR{chain_letter}V', f'CDR3{chain_letter}'])\n",
    "df = df[df[f'CDR3{chain_letter}'].apply(len)>5]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load HLA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlas = pd.read_csv('data/hladata.csv', index_col=0)\n",
    "hlas = flatten_hlas(hlas)\n",
    "hlas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmethod = 'fisher'\n",
    "mincount = 2\n",
    "max_edits = 2\n",
    "max_tcrdist = 10 if chain == 'alpha' else 15\n",
    "clustering = 'leiden'\n",
    "clustering_kwargs = dict(resolution=0.1,\n",
    "                         objective_function='CPM',\n",
    "                         n_iterations=4)\n",
    "min_donors = 4\n",
    "\n",
    "newpath = f'output/{dir_out}' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter clones < mincount\n",
    "df = df[df['clonal_count']>=mincount]\n",
    "# only keep samples found in both datasets\n",
    "print(set(df['UIN'])-set(hlas.index))\n",
    "df = df[df['UIN'].isin(hlas.index)]\n",
    "hlas = hlas.loc[list(set(df['UIN']))]\n",
    "len(df['UIN'].unique()), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter hlas < min_donors\n",
    "hlas = hlas[hlas.columns[hlas.sum(axis=0)>=min_donors]]\n",
    "# filter MHC class\n",
    "if mhc_class == 'both':\n",
    "    pass\n",
    "elif mhc_class == 'I':\n",
    "    hlas = hlas[hlas.columns[~hlas.columns.str.startswith('D')]]\n",
    "elif mhc_class == 'II':\n",
    "    hlas = hlas[hlas.columns[hlas.columns.str.startswith('D')]]\n",
    "else:\n",
    "    raise NotImplementedError(\"mhc_class needs to be in ['both', 'I', 'II']\")\n",
    "len(hlas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = metaclonotypist(df, chain=chain,\n",
    "                           max_tcrdist=max_tcrdist, max_edits=max_edits,\n",
    "                           clustering=clustering, clustering_kwargs=clustering_kwargs)\n",
    "clusters['Sample.ID'] = df.loc[clusters.index]['UIN']\n",
    "clusters[f'CDR3{chain_letter}'] = df.loc[clusters.index][f'CDR3{chain_letter}']\n",
    "len(clusters['cluster'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter clusters < min_donors\n",
    "ndonors = clusters.groupby('cluster').apply(lambda cluster: len(cluster['Sample.ID'].unique()))\n",
    "clusters = clusters[clusters['cluster'].isin(ndonors[(ndonors >= min_donors)].index)]\n",
    "len(clusters['cluster'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_association = hla_association(clusters, hlas,\n",
    "                                      method=testmethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_association.to_csv(f'output/{dir_out}/clusterassociation_{chain}_mhc{mhc_class}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmetaclones = len(cluster_association[cluster_association['significant']]['cluster'].unique())\n",
    "cluster_association['significant'].sum(), nmetaclones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_association_noinf = cluster_association.replace(np.inf, 400, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HLA shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle hlas\n",
    "hlas_shuffled = hlas.copy()\n",
    "hlas_shuffled.index = np.random.permutation(hlas_shuffled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_association_shuffled = hla_association(clusters, hlas_shuffled, method=testmethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_association_shuffled.to_csv(f'output/{dir_out}/clusterassociation_shuffled_{chain}_mhc{mhc_class}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_association_shuffled['significant'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_association_shuffled_noinf = cluster_association_shuffled.replace(np.inf, 400, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and saving of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(4.5, 2.5), ncols=2, sharex=True, sharey=True)\n",
    "sns.scatterplot(ax=axes[0], data=cluster_association_noinf,\n",
    "                x='odds_ratio',\n",
    "                y=-np.log10(cluster_association['pvalue']),\n",
    "                hue='significant',\n",
    "                s=5)\n",
    "axes[0].text(0.1, 0.5, f'$n={nmetaclones}$', transform=axes[0].transAxes)\n",
    "sns.scatterplot(ax=axes[1], data=cluster_association_shuffled_noinf,\n",
    "                x='odds_ratio',\n",
    "                y=-np.log10(cluster_association_shuffled['pvalue']),\n",
    "                hue='significant',\n",
    "                s=5)\n",
    "axes[0].set_title('Data')\n",
    "axes[1].set_title('Shuffled HLA')\n",
    "for ax in axes:\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('p value')\n",
    "    ax.set_xlabel('odds ratio')\n",
    "    ax.legend(loc='upper left', title='significant')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'output/{dir_out}/volcano_plot_{chain}_mhc{mhc_class}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_metaclones = cluster_association[cluster_association['significant']]\n",
    "hla_metaclones.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "hla_counts = hla_metaclones['hla'].value_counts()\n",
    "ax.bar(hla_counts.index, hla_counts)\n",
    "plt.xticks(rotation=90);\n",
    "plt.ylabel('# HLA-associated metaclonotypes')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'output/{dir_out}/hla_association_{chain}_mhc{mhc_class}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_clusters = clusters[(clusters['cluster'].isin(hla_metaclones['cluster']))].reset_index()\n",
    "print(len(sig_clusters))\n",
    "sig_clusters = sig_clusters.merge(hla_metaclones, on='cluster')\n",
    "hla_match = [hlas.loc[row['Sample.ID']][row['hla']] for ind, row in sig_clusters.iterrows()]\n",
    "sig_clusters = sig_clusters.iloc[hla_match]\n",
    "len(sig_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in hla_metaclones['cluster'].unique():\n",
    "    tcrs = df.loc[sig_clusters[(sig_clusters['cluster']==cluster)]['index']]\n",
    "    tcrs[f'CDR3{chain_letter}'].apply \n",
    "    pp.seqlogos_vj(tcrs, cdr3_column=f'CDR3{chain_letter}',\n",
    "                   v_column=f'TR{chain_letter}Vshort',\n",
    "                   j_column=f'TR{chain_letter}J')\n",
    "    plt.gcf().savefig(f'output/{dir_out}/{chain}_mhc{mhc_class}_{cluster}_seqlogo.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_metaclones_unique = hla_metaclones.sort_values('pvalue'\n",
    "                            ).drop_duplicates(subset='cluster', keep='first'\n",
    "                            ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hla_metaclones_unique)\n",
    "hla_metaclones_unique.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (cluster, hla) in hla_metaclones_unique[['cluster', 'hla']].iterrows():\n",
    "    seqs = df.loc[clusters[(clusters['cluster']==cluster)].index]\n",
    "\n",
    "    neighbors = prs.nearest_neighbor_tcrdist(seqs,\n",
    "                                             max_edits=max_edits,\n",
    "                                             max_tcrdist=max_tcrdist,\n",
    "                                             chain=chain)\n",
    "    edges = np.array(neighbors)[:, :2]\n",
    "    g = igraph.Graph(edges, n=len(seqs))\n",
    "    g.simplify()\n",
    "\n",
    "    g.vs['ID'] = list(seqs['UIN'])\n",
    "    \n",
    "    sample_ids = clusters[clusters['cluster'] == cluster]['Sample.ID']\n",
    "    g.vs['HLA'] = hlas.loc[sample_ids, hla].apply(lambda x: 'o' if x else '')\n",
    "    \n",
    "    g.es['weight'] = 1.0*np.exp(-np.array(neighbors[:, 2])/max_tcrdist)\n",
    "    c0 = mpl.colors.to_rgba('C0')\n",
    "    c1 = mpl.colors.to_rgba('C1')\n",
    "    g.vs['color'] = hlas.loc[sample_ids, hla].apply(lambda x: c1 if x else c0)\n",
    "    \n",
    "    edge_idx = np.array([(e.source, e.target) for e in g.es])\n",
    "    same_sample = (np.array(seqs.iloc[edge_idx[:, 0]]['UIN'])\n",
    "                   == np.array(seqs.iloc[edge_idx[:, 1]]['UIN']))\n",
    "    c2 = mpl.colors.to_rgba('C3')\n",
    "    c3 = mpl.colors.to_rgba('.3')\n",
    "    g.es['color'] = [c2 if s else c3 for s in same_sample]\n",
    "    \n",
    "    width, height = 2.0, 1.0\n",
    "    scale = 10.0\n",
    "    layout = g.layout('kk',\n",
    "                      minx=np.zeros(len(seqs)),\n",
    "                      maxx=scale*width*np.ones(len(seqs)),\n",
    "                      miny=np.zeros(len(seqs)),\n",
    "                      maxy=scale*height*np.ones(len(seqs)))\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "    igraph.plot(g, target=ax,\n",
    "                layout=layout,\n",
    "                vertex_frame_width=0,\n",
    "                vertex_size=2,\n",
    "                edge_width=g.es['weight'])\n",
    "    fig.tight_layout(pad=0.0)\n",
    "    fig.savefig(f'output/{dir_out}/{chain}_mhc{mhc_class}_{cluster}_graph.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (cluster, hla) in hla_metaclones_unique[['cluster', 'hla']].iterrows():\n",
    "    seqs = df.loc[clusters[(clusters['cluster']==cluster)].index]\n",
    "\n",
    "    neighbors = prs.nearest_neighbor_tcrdist(seqs,\n",
    "                                             max_edits=max_edits,\n",
    "                                             max_tcrdist=max_tcrdist,\n",
    "                                             chain=chain)\n",
    "    edges = np.array(neighbors)[:, :2]\n",
    "    g = igraph.Graph(edges, n=len(seqs))\n",
    "    g.simplify()\n",
    "\n",
    "    unique_ids = seqs['UIN'].unique()\n",
    "    id_to_color = dict(zip(unique_ids, plt.colormaps['gist_rainbow'](np.linspace(0, 1, len(unique_ids)))))\n",
    "    id_to_color = {id_: tuple(color) for id_, color in id_to_color.items()}\n",
    "    g.vs['color'] = list(seqs['UIN'].map(id_to_color))\n",
    "    \n",
    "    width, height = 2.0, 1.0\n",
    "    scale = 10.0\n",
    "    layout = g.layout('kk',\n",
    "                      minx=np.zeros(len(seqs)),\n",
    "                      maxx=scale*width*np.ones(len(seqs)),\n",
    "                      miny=np.zeros(len(seqs)),\n",
    "                      maxy=scale*height*np.ones(len(seqs)))\n",
    "    fig, ax = plt.subplots(figsize=(width, height))\n",
    "    igraph.plot(g, target=ax,\n",
    "                layout=layout,\n",
    "                vertex_frame_width=0,\n",
    "                edge_width=10.0/len(seqs),\n",
    "                vertex_size=2, \n",
    "               vertex_color=g.vs['color']) \n",
    "    fig.tight_layout(pad=0.0)\n",
    "    fig.savefig(f'output/{dir_out}/{chain}_mhc{mhc_class}_{cluster}_graph2.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_metaclones_unique['Vs'] = hla_metaclones_unique['cluster'].apply(lambda x:\n",
    "                                    '|'.join(df.loc[clusters[(clusters['cluster']==x)].index]\n",
    "                                             [f'TR{chain_letter}Vshort'].unique()))\n",
    "hla_metaclones_unique.head(81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in hla_metaclones_unique['cluster']:\n",
    "    seqs = df.loc[clusters[(clusters['cluster']==x)].index][f'CDR3{chain_letter}']\n",
    "if seqs.empty:\n",
    "    print(f\"No sequences found for cluster {x}.\")\n",
    "else:\n",
    "    try:\n",
    "        prs.seqs_to_consensus(seqs)\n",
    "    except EnvironmentError:\n",
    "        print(seqs)\n",
    "        aligned = prs.align_seqs([str(s) for s in seqs])\n",
    "        print(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_consensus(cluster):\n",
    "    seqs = df.loc[clusters[(clusters['cluster'] == cluster)].index][f'CDR3{chain_letter}']\n",
    "    if seqs.empty:\n",
    "        print(f\"No sequences found for cluster {cluster}.\")\n",
    "        return None \n",
    "    try:\n",
    "        return prs.seqs_to_consensus(seqs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cluster {cluster}: {e}\")\n",
    "        return None\n",
    "\n",
    "hla_metaclones_unique['consensus'] = hla_metaclones_unique['cluster'].apply(generate_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_regex(cluster):\n",
    "    seqs = df.loc[clusters[clusters['cluster'] == cluster].index][f'CDR3{chain_letter}']\n",
    "    if seqs.empty:\n",
    "        print(f\"No sequences found for cluster {cluster}.\")\n",
    "        return None\n",
    "    try:\n",
    "        return prs.seqs_to_regex(seqs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cluster {cluster}: {e}\")\n",
    "        return None\n",
    "\n",
    "hla_metaclones_unique['regex'] = hla_metaclones_unique['cluster'].apply(get_cluster_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_metaclones_unique['CDR3s'] = hla_metaclones_unique['cluster'].apply(lambda x:\n",
    "                                    '|'.join(df.loc[\n",
    "                                    clusters[(clusters['cluster']==x)].index][f'CDR3{chain_letter}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hla_metaclones_unique.to_csv(f'output/{dir_out}/hlametaclonotypes_{chain}_mhc{mhc_class}.csv')\n",
    "# used as Supplementary Tables S4-5 and S7-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze metaclonotype coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['nassociations', len(hla_metaclones)],\n",
    "        ['nmetaclones', len(hla_metaclones['cluster'].unique())],\n",
    "        ['nshuffled', cluster_association_shuffled['significant'].sum()],\n",
    "        ['clustered_fraction', len(clusters)/len(df)],\n",
    "        ['sig_clonotype_fraction', len(sig_clusters)/len(df)],\n",
    "        ['sig_read_fraction', df.loc[sig_clusters['index']]['clonal_count'].sum()/df['clonal_count'].sum()],\n",
    "        ['id_fraction', len(sig_clusters['Sample.ID'].unique())/len(df['UIN'].unique())]\n",
    "       ]\n",
    "index, values = list(zip(*data))\n",
    "s = pd.Series(index=index, data=values, name='results')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv(f'output/{dir_out}/metaclonotype_coverage_{chain}_mhc{mhc_class}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
